{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDriIbfa5lwD"
      },
      "source": [
        "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvR7ppk77v31"
      },
      "source": [
        "### Importing Skin Cancer Data\n",
        "#### To do: Take necessary actions to read the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      },
      "source": [
        "### Importing all the important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8xCQuELWms"
      },
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import PIL\n",
        "from glob import glob\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import Sequential\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYpVPmT5z7AP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd484fe-3de1-4724-f1b3-b4eae630f4b9"
      },
      "source": [
        "## If you are using the data by mounting the google drive, use the following :\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "##Ref:https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/CNN_assignment.zip\" > /dev/null"
      ],
      "metadata": {
        "id": "_thBdM2rF6aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67148099-1f02-4eb0-ae4c-87a54696efff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace Skin cancer ISIC The International Skin Imaging Collaboration/Test/actinic keratosis/ISIC_0010512.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpUsRQwOOL72"
      },
      "source": [
        "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D57L-ovIKtI4"
      },
      "source": [
        "# Defining the path for train and test images\n",
        "## Todo: Update the paths of the train and test dataset\n",
        "data_dir_train = pathlib.Path(\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\")\n",
        "data_dir_test = pathlib.Path('/content/Skin cancer ISIC The International Skin Imaging Collaboration/Test/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqksN1w5Fu-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3972a07-6740-4f2c-85bf-83bc25571479"
      },
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2239\n",
            "118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8HkfW3jPJun"
      },
      "source": [
        "### Load using keras.preprocessing\n",
        "\n",
        "Let's load these images off disk using the helpful image_dataset_from_directory utility."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data** **Visualization**"
      ],
      "metadata": {
        "id": "Lv2VGklLHO62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize any one instance of all the class present in the dataset.\n",
        "\n",
        "\n",
        "# List out all the classes of skin cancer and store them in a list. \n",
        "# You can find the class names in the class_names attribute on these datasets. \n",
        "# These correspond to the directory names in alphabetical order.\n",
        "\n",
        "\n",
        "# image_dataset_from_directory() will return a tf.data.Dataset that yields batches of images from the subdirectories.\n",
        "# label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes), \n",
        "# representing a one-hot encoding of the class index.\n",
        "\n",
        "\n",
        "image_dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,image_size=(180,180),\n",
        "                                                                    label_mode='categorical',seed=123)\n",
        "\n",
        "#all the classes of Skin Cancer\n",
        "class_names = image_dataset.class_names\n",
        "\n",
        "#Dictionary to store the path of image as per the class\n",
        "files_path_dict = {}\n",
        "\n",
        "for c in class_names:\n",
        "    files_path_dict[c] = list(map(lambda x:str(data_dir_train)+'/'+c+'/'+x,os.listdir(str(data_dir_train)+'/'+c)))\n",
        "    \n",
        "#Visualize image \n",
        "plt.figure(figsize=(14,14))\n",
        "index = 0\n",
        "for c in class_names:\n",
        "    path_list = files_path_dict[c][:3]\n",
        "    index += 1\n",
        "    plt.subplot(3,3,index)\n",
        "    plt.imshow(load_img(path_list[2],target_size=(180,180)))\n",
        "    plt.title(c)\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "9EObXABMHN37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBKZG3jPcMc"
      },
      "source": [
        "### Lets Visualize distribution of classes in the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLfcXcZ9LjGv"
      },
      "source": [
        "def class_distribution_count(directory):\n",
        "    \n",
        "    #count number of image in each classes\n",
        "    count= []\n",
        "    for path in pathlib.Path(directory).iterdir():\n",
        "        if path.is_dir():\n",
        "            count.append(len([name for name in os.listdir(path)\n",
        "                               if os.path.isfile(os.path.join(path, name))]))\n",
        "    \n",
        "    #name of the classes\n",
        "    sub_directory = [name for name in os.listdir(directory)\n",
        "                    if os.path.isdir(os.path.join(directory, name))]\n",
        "    \n",
        "    #return dataframe with image count and class.\n",
        "    return pd.DataFrame(list(zip(sub_directory,count)),columns =['Class', 'No. of Image'])\n",
        "\n",
        "df = class_distribution_count(data_dir_train)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's Visualize the Number of image in each class with graph."
      ],
      "metadata": {
        "id": "pyTrP1UUJgTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=\"No. of Image\", y=\"Class\", data=df,\n",
        "            label=\"Class\")"
      ],
      "metadata": {
        "id": "HhyKSFTLJe4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choosing an appropriate data augmentation strategy to resolve underfitting/overfitting"
      ],
      "metadata": {
        "id": "_RtMos6PKOH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing Augmentor\n",
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "mK69zRfkKcyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset_Path=\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(training_dataset_Path + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500)  #Adding 500 samples per class to make sure that none of the classes are sparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frJ_B-PtKc1h",
        "outputId": "915a3fc5-daf2-432b-e862-b089a4de3016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 114 image(s) found.\n",
            "Output directory set to /content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/actinic keratosis/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7FA56A4216A0>: 100%|██████████| 500/500 [00:16<00:00, 30.01 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 376 image(s) found.\n",
            "Output directory set to /content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/basal cell carcinoma/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x7FA56A3B8160>: 100%|██████████| 500/500 [00:25<00:00, 20.00 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 95 image(s) found.\n",
            "Output directory set to /content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/dermatofibroma/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7FA56A481FD0>: 100%|██████████| 500/500 [00:23<00:00, 21.16 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 438 image(s) found.\n",
            "Output directory set to /content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/melanoma/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=1024x768 at 0x7FA56A4EED60>: 100%|██████████| 500/500 [01:17<00:00,  6.47 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 357 image(s) found.\n",
            "Output directory set to /content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/nevus/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=1504x1129 at 0x7FA5865FD5E0>: 100%|██████████| 500/500 [01:17<00:00,  6.42 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 462 image(s) found.\n",
            "Output directory set to /content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/pigmented benign keratosis/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x7FA5865B7B20>: 100%|██████████| 500/500 [00:15<00:00, 31.94 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 77 image(s) found.\n",
            "Output directory set to /content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/seborrheic keratosis/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x768 at 0x7FA56A3E2460>:  17%|█▋        | 83/500 [00:08<00:33, 12.43 Samples/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's count total number of image generated by Augmentor\n",
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "metadata": {
        "id": "umjZrcNbKbye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model** **Building**"
      ],
      "metadata": {
        "id": "X10cMLzCMX8-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5f5y43GPog1"
      },
      "source": [
        "Use 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train dataset"
      ],
      "metadata": {
        "id": "rBugTb5tM3vc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1BWmDzr7w-5"
      },
      "source": [
        "## Write your train dataset here\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train, batch_size=32,\n",
        "                                                               image_size=(180,180), label_mode='categorical',\n",
        "                                                               seed=123,subset=\"training\",\n",
        "                                                               validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### validation dataset "
      ],
      "metadata": {
        "id": "fyYEGMTXM6-E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYch6-SR-i2g"
      },
      "source": [
        "## Write your validation dataset here\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,\n",
        "                                                            image_size=(180,180), label_mode='categorical',\n",
        "                                                            seed=123,subset=\"validation\",\n",
        "                                                            validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cAZPYaeQjQy"
      },
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk0RV7G7-nad"
      },
      "source": [
        "# tf.data.experimental.AUTOTUNE = defines appropriate number of processes that are free for working.\n",
        "\n",
        "# Dataset.cache() = keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "# Dataset.prefetch() = overlaps data preprocessing and model execution while training.\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEAF6-sRyz8"
      },
      "source": [
        "### Create the model\n",
        "#### Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ync9xoW7GZgn"
      },
      "source": [
        "### Your code goes here\n",
        "\n",
        "#CNN Model Architecture\n",
        "\n",
        "#Sequential allows you to create models layer-by-layer  \n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.experimental.preprocessing.Rescaling(1./255,input_shape=(180,180,3)))   #Rescaling Layer\n",
        "\n",
        "#First Convulation layer\n",
        "model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Second Convulation Layer\n",
        "model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Third Convulation Layer\n",
        "model.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Dropout layer with 50% Fraction of the input units to drop.\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "#Flatten Layer\n",
        "##Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "\n",
        "#Dropout layer with 25% Fraction of the input units to drop.\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "#Dense Layer with softmax activation function.\n",
        "#Softmax is an activation function that scales numbers/logits into probabilities.\n",
        "model.add(layers.Dense(len(class_names),activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's vizualizing the model \n",
        "\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "kR4HMpTOQxDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDKzJmHwSCtt"
      },
      "source": [
        "### Compile the model\n",
        "Choose an appropirate optimiser and loss function for model training "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Todo, choose an appropirate optimiser and loss function\n",
        "#Adam optimization: is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
        "#categorical_crossentropy: Used as a loss function for multi-class classification model where there are two or more output labels.\n",
        "\n",
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "#ModelCheckpoint callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval,\n",
        "#so the model or weights can be loaded later to continue the training from the state saved.\n",
        "checkpoint = ModelCheckpoint(\"model.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
        "\n",
        "#Stop training when a monitored metric has stopped improving.\n",
        "earlystop = EarlyStopping(monitor=\"val_accuracy\",patience=5,mode=\"auto\",verbose=1)"
      ],
      "metadata": {
        "id": "9f3wI4aXRH4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZGWN4MZGhtJ"
      },
      "source": [
        "# View the summary of all layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljD_83rwSl5O"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkfw2rJXGlYC"
      },
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  callbacks=[checkpoint,earlystop]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3679V8OShSE"
      },
      "source": [
        "### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1xkgk5nGubz"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As per the above model Training accuracy and validation accuracy increases.\n",
        "* Model overfitting issue is solved.\n",
        "* Class rebalance helps in augmentation and achieving the best Training and validation accuracy."
      ],
      "metadata": {
        "id": "A5--nGnUpTe-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Prediction**"
      ],
      "metadata": {
        "id": "RzF6OgoWjt_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Test_image_path = os.path.join(data_dir_test, class_names[1], '*')\n",
        "Test_image = glob(Test_image_path)\n",
        "Test_image = load_img(Test_image[1],target_size=(180,180,3))\n",
        "plt.imshow(Test_image)\n",
        "plt.grid(False)\n",
        "\n",
        "img = np.expand_dims(Test_image,axis=0)\n",
        "pred = model.predict(img)\n",
        "pred = np.argmax(pred)\n",
        "pred_class = class_names[pred]\n",
        "print(\"Actual Class \"+ class_names[1] +'\\n'+ \"Predictive Class \"+pred_class )"
      ],
      "metadata": {
        "id": "n3Yb7xBljxJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV2BHg1dWrdY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}